{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center;\"><b>«Практическое занятие по дисперсионному анализу и A/B тестам»</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.power import tt_solve_power\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Дисперсионный анализ\n",
    "\n",
    "Рассмотренный ранее **t-критерий Стьюдента** (равно как и его непараметрические аналоги) предназначен для сравнения исключительно **двух совокупностей**. В таком случае мы можем применять однофакторный дисперсионный анализ.  Та переменная, которая будет разделять наших испытуемых или наблюдения на группы (номинативная переменная с нескольким градациями) называется **независимой переменной**. А та количественная переменная, по степени выраженности которой мы сравниваем группы, называется **зависимая переменная**. \n",
    "\n",
    "\n",
    "$$ SS_{total} = \\sum_{j=1}^{p}{\\sum_{i=1}^{n_j}{(x_{ij} - \\bar{x})^2}} = SS_{between} + SS_{within} $$\n",
    "$$ SS_{between} = \\sum_{j=1}^{p}{n_j{(\\bar{x}_j - \\bar{x})^2}} $$\n",
    "$$ SS_{within} = \\sum_{j=1}^{p}{\\sum_{i=1}^{n_j}{(x_{ij} - \\bar{x}_j)^2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выборки которые надо сравнить\n",
    "data =\\\n",
    "    pd.DataFrame({\n",
    "        'a': [3, 1, 2],\n",
    "        'b': [5, 3, 4],\n",
    "        'c': [7, 6, 5]\n",
    "    })\n",
    "data.boxplot()\n",
    "print('Нулевая гипотеза:', '='.join(data))\n",
    "print('Альтернативная гипотеза:', f'!({\"=\".join(data)})')\n",
    "# Общая средняя\n",
    "grand_mean = data.values.flatten().mean()\n",
    "# Общая сумма квадратов sst = ssb + ssw\n",
    "sst = sum((val - grand_mean)**2 for val in data.values.flatten())\n",
    "# Отклонение групповых средний от общей средней\n",
    "ssb = sum(data[group].size * (group_mean - grand_mean) ** 2 for group, group_mean in data.mean().items())\n",
    "# Отклонения значений внутри группы от средней группы\n",
    "ssw = sum(sum((x - group_mean)**2 for x in data[group]) for group, group_mean in data.mean().items())\n",
    "\n",
    "groups = data.shape[1]\n",
    "# Степени свободы\n",
    "dfb = groups - 1\n",
    "dfw = data.size - groups\n",
    "# Межгрупповой средний квадрат\n",
    "mssb = ssb/dfb\n",
    "# Внутригрупповой средний квадрат\n",
    "mssw = ssw/dfw\n",
    "\n",
    "f_value = mssb/mssw\n",
    "\n",
    "p = st.f.sf(f_value, dfb, dfw)\n",
    "print('Результат:')\n",
    "if p < 0.05:\n",
    "    print('отклоняем нулевую гипотезу')\n",
    "else:\n",
    "    print('НЕ отклоняем нулевую гипотезу')\n",
    "print(f\"Полученное f-значение {f_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение F-значения\n",
    "from IPython.display import Image\n",
    "Image('fisher_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, на распределение в нашем случае\n",
    "- https://gallery.shinyapps.io/dist_calc/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем синтетический датасет с данными. У нас есть наблюдения по 4 группам. Предположим, что это данные о результатах исследования эффективности четырех препаратов и нам нужно определить если между этими результатами статистически значимая разница."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =\\\n",
    "    pd.DataFrame([[25, 45, 30, 54],\n",
    "                  [30, 55, 29, 60],\n",
    "                  [28, 29, 33, 51],\n",
    "                  [36, 56, 37, 62],\n",
    "                  [29, 40, 27, 73]],\n",
    "                 columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(df.reset_index(), id_vars=['index'], value_vars=['A', 'B', 'C', 'D'])\n",
    "df_melt.columns = ['index', 'treatments', 'value']\n",
    "df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='treatments', y='value', data=df_melt, color='#99c2a2')\n",
    "ax = sns.swarmplot(x=\"treatments\", y=\"value\", data=df_melt, color='#7d0013')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "fvalue, pvalue = stats.f_oneway(df['A'], df['B'], df['C'], df['D'])\n",
    "\n",
    "print('Статистика=%.3f, p=%.6f' % (fvalue, pvalue))\n",
    "if p > 0.05:\n",
    "    print('Не отклоняем нулевую гипотезу, средние, вероятно, одинаковые')\n",
    "else:\n",
    "    print('Отклоняем нулевую гипотезу, средние, вероятно, различаются')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему мы не можем применить t-критерий для более двух выборок применяя его попарно к каждой выбрке**\n",
    "\n",
    "Чтобы выяснить это, сделаем эксперемент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from scipy.stats import t\n",
    "\n",
    "def pair_t(samples, alpha):\n",
    "    '''Парный t-критерий, если все выборки равны, возвращает True'''\n",
    "    n_samples = samples.shape[0]\n",
    "    # https://ru.wikipedia.org/wiki/Сочетание\n",
    "    n_combinations = n_samples*(n_samples - 1)//2\n",
    "    result = np.zeros(n_combinations, dtype=bool)\n",
    "    k = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            N = samples[i].size\n",
    "            std_err = np.sqrt((samples[i].std()**2) /\n",
    "                              N + (samples[j].std()**2)/N)\n",
    "            t_value = (samples[i].mean() + samples[j].mean())/std_err\n",
    "            p = t.sf(t_value, N-2)\n",
    "            result[k] = p >= alpha\n",
    "            k += 1\n",
    "    return np.all(result)\n",
    "\n",
    "\n",
    "def pair_t_test(repeat, n_samples, sample_size, ax, alpha=0.05):\n",
    "    '''\n",
    "    функция показывает, сколько у нас будет ложных результатов, при парном сравнение множества выборок\n",
    "    с помощью t-критерия\n",
    "\n",
    "    repeat - количество повторов\n",
    "    n_samples - количество выборок в каждом повторе\n",
    "    sample_size - размер выборки\n",
    "\n",
    "    ax - для рисования\n",
    "    alpha = (1 - (p-уровень значимости))\n",
    "    '''\n",
    "    result = np.zeros(repeat, dtype=bool)\n",
    "    for i in range(repeat):\n",
    "        samples = random.randn(n_samples, sample_size)\n",
    "        result[i] = pair_t(samples, alpha)\n",
    "\n",
    "    unique, counts = np.unique(result, return_counts=True)\n",
    "    percentage = counts/result.size\n",
    "    ax.pie(percentage, labels=unique, autopct='%.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 4))\n",
    "n_samples = [2, 4, 8, 16]\n",
    "fig.suptitle('Процент ошибок при попарном сравнение выборок t-критерием')\n",
    "\n",
    "for n, ax in zip(n_samples, axs):\n",
    "    pair_t_test(1000, n, 30, ax)\n",
    "    ax.set_title(f'Выборки: {n}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы и ожидаем, степень ошибки равна **5%**, при сравнение **двух выборок** из одной ГС с помощью t-критерия с p-уровнем значимости **95%**. Если мы возмём **4** выборки, и сравним их попарно, то ошибка возрастёт в **4** раза до **20%**. При **8** выборок, наша ошибка возрасла почти в **9** раз до **46%**. **16** выборок дают увеличение ошибки до **80%** ( в 16 раз), что совершенно неприемлемо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 4))\n",
    "n_samples = [2, 4, 8, 16]\n",
    "fig.suptitle('Процент ошибок при попарном сравнение выборок t-критерием с корректировкой уровня значимости')\n",
    "\n",
    "for n, ax in zip(n_samples, axs):\n",
    "    alpha = 0.05/((n*(n-1))/2) # делим на число сравнений = ((n*(n-1))/2) - поправка Бонферрони \n",
    "    pair_t_test(1000, n, 30, ax, alpha)\n",
    "    ax.set_title(f'Выборки: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в данном мы **уменьшаем шанс получить ошибку I рода, но увеличиваем шанс на ошибку II рода**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "\n",
    "plt.fill_between(x=np.arange(-4,-2,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(-4,-2,0.01)) ,\n",
    "                 facecolor='red',\n",
    "                 alpha=0.35)\n",
    "\n",
    "plt.fill_between(x=np.arange(-2,2,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(-2,2,0.01)) ,\n",
    "                 facecolor='grey',\n",
    "                 alpha=0.35)\n",
    "\n",
    "plt.fill_between(x=np.arange(2,4,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(2,4,0.01)) ,\n",
    "                 facecolor='red',\n",
    "                 alpha=0.5)\n",
    "\n",
    "plt.fill_between(x=np.arange(-4,-2,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(-4,-2,0.01),loc=3, scale=2) ,\n",
    "                 facecolor='grey',\n",
    "                 alpha=0.35)\n",
    "\n",
    "plt.fill_between(x=np.arange(-2,2,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(-2,2,0.01),loc=3, scale=2) ,\n",
    "                 facecolor='blue',\n",
    "                 alpha=0.35)\n",
    "\n",
    "plt.fill_between(x=np.arange(2,10,0.01), \n",
    "                 y1= st.norm.pdf(np.arange(2,10,0.01),loc=3, scale=2),\n",
    "                 facecolor='grey',\n",
    "                 alpha=0.35)\n",
    "\n",
    "plt.text(x=-0.8, y=0.15, s= \"Нулевая\\nгипотеза\")\n",
    "plt.text(x=2.5, y=0.13, s= \"Альтернативная\\nгипотеза\")\n",
    "plt.text(x=2.1, y=0.01, s= \"Ошибка\\nпервого\\nрода\")\n",
    "plt.text(x=-3.2, y=0.01, s= \"Ошбика\\nпервого\\nрода\")\n",
    "plt.text(x=0, y=0.02, s= \"Ошибка\\nвторого рода\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_solve_power(effect_size = 0.5,\n",
    "               alpha = 0.01,\n",
    "               power = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['A','B','C','D']\n",
    "names = [];\n",
    "for k1 in range (len(groups)):\n",
    "    for k2 in range(len(df['A'])):\n",
    "        names.append(groups[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey = pairwise_tukeyhsd(endog=pd.concat([df['A'], df['B'],df['C'],df['D']]).values,\n",
    "                          groups=names,\n",
    "                          alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey.plot_simultaneous(comparison_name=\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест Краскела-Уоллиса\n",
    "Непараметрическая альтернатива одномерному (межгрупповому) дисперсионному анализу. Он используется для сравнения трех или более выборок, и проверяет нулевые гипотезы, согласно которым различные выборки были взяты из одного и того же распределения, или из распределений с одинаковыми медианами\n",
    "\n",
    "Допущения\n",
    "\n",
    "* Наблюдения независимы друг от друга.\n",
    "* Наблюдения можно проранжировать.\n",
    "\n",
    "Гипотеза\n",
    "\n",
    "* H0: Все распределения одинаковы.\n",
    "* H1: Одно или несколько распределений различаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [6.873, 4.817, 4.121, -0.045, -0.055, -0.0436, 4.360, -0.478, -0.0637, -0.089]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "data3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\n",
    "\n",
    "stat, p = st.kruskal(data1, data2, data3)\n",
    "\n",
    "print(f\"Статистика = {stat:.3f}, p = {p:.3f}\")\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Не отклоняем нулевую гипотезу, распределения, вероятно, одинаковые')\n",
    "else:\n",
    "    print('Отклоняем нулевую гипотезу, распределения, вероятно, различаются')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(data1, data2, data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "sp.posthoc_dunn(data, p_adjust = 'bonferroni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тесты на нормальность данных\n",
    "### Тест Шапиро-Уилка\n",
    "Проверяет распределены ли данные по нормальному закону.\n",
    "\n",
    "Допущения\n",
    "\n",
    "* Наблюдения независимы друг от друга.\n",
    "\n",
    "Гипотеза\n",
    "\n",
    "* H0: Данные распределены по нормальному закону.\n",
    "* H1: Данные не распределены по нормальному закону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "\n",
    "stat, p = st.shapiro(data)\n",
    "\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Вероятно нормальное распределение')\n",
    "else:\n",
    "    print('Вероятно не нормальное распределение')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест Андерсона-Дарлинга\n",
    "Проверяет распределены ли данные по нормальному закону.\n",
    "\n",
    "Допущения\n",
    "\n",
    "* Наблюдения независимы друг от друга.\n",
    "\n",
    "Гипотеза\n",
    "\n",
    "* H0: Данные распределены по нормальному закону.\n",
    "* H1: Данные не распределены по нормальному закону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "result = st.anderson(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stat=%.3f' % (result.statistic))\n",
    "for i in range(len(result.critical_values)):\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "    if result.statistic < cv:\n",
    "        print('Вероятно нормальное на уровне %.1f%%' % (sl))\n",
    "    else:\n",
    "        print('Вероятно не нормальное на уровне %.1f%%' % (sl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест Колмогорова-Смирнова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset of 100 values that follow a Poisson distribution with mean=5\n",
    "data = np.random.normal(0,1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform Kolmogorov-Smirnov test\n",
    "stat, p = st.kstest(data, 'norm')\n",
    "print(f\"Статистика = {stat:.5f}, p = {p:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate two datasets\n",
    "data1 = np.random.randn(100)\n",
    "data2 = np.random.lognormal(3, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = st.ks_2samp(data1, data2)\n",
    "print(f\"Статистика = {stat:.5f}, p = {p:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример проведения A/B теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте представим, что вы работаете в команде разработчиков **онлайн-бизнеса электронной коммерции**. UX-дизайнер очень усердно работал над новой версией страницы продукта в надежде, что это приведет к более высокому коэффициенту конверсии. Менеджер по продукту сказал вам, что **текущий коэффициент конверсии** составляет около **13%** в среднем в течение года, и что команда была бы рада **увеличению на 2%**, что означает что новый дизайн будет считаться успешным, если он поднимет коэффициент конверсии до 15%.\n",
    "\n",
    "Прежде чем внедрять изменение, команде было бы удобнее протестировать его на небольшом количестве пользователей, чтобы увидеть, как оно работает, поэтому вы предлагаете провести **A/B-тест** на подмножестве пользователей вашей пользовательской базы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Планирование эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде всего, необходимо сформулировать нулевую гипотезу, чтобы не ошибиться при интерпретации результатов.\n",
    "\n",
    "Поскольку мы не знаем, будет ли новый дизайн работать лучше или хуже (или будет таким же?), как наш текущий дизайн, мы выберем <a href=\"https://en.wikipedia.org/wiki/One-_and_two-tailed_tests\">**двусторонний тест**</a>:\n",
    "\n",
    "$$H_0: p = p_0$$\n",
    "$$H_a: p \\ne p_0$$\n",
    "\n",
    "где $p$ и $p_0$ — коэффициент конверсии нового и старого дизайна соответственно. Мы также установим **уровень достоверности 95%**:\n",
    "\n",
    "$$\\alpha = 0,05$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нашего теста нам понадобятся **две группы**:\n",
    "* Контрольная группа (`control`)  - им будет показан старый дизайн\n",
    "* Экспериментальная группа (`treatment`) — им будет показан новый дизайн.\n",
    "\n",
    "Это будет наша *Независимая переменная*. Причина, по которой у нас есть две группы, несмотря на то, что мы знаем базовый коэффициент конверсии, заключается в том, что мы хотим контролировать другие переменные, которые могут повлиять на наши результаты, такие как сезонность: имея «контрольную» группу, мы можем напрямую сравнивать их результаты с экспериментальной группой, потому что единственное систематическое различие между группами заключается в дизайне страницы продукта, и поэтому мы можем отнести любые различия в результатах к дизайну.\n",
    "\n",
    "Для нашей *зависимой переменной* (т.е. того, что мы пытаемся измерить) нас интересует \"коэффициент конверсии\". Мы можем закодировать это для каждого сеанса пользователя с помощью двоичной переменной:\n",
    "* `0` - Пользователь не покупал продукт в течение данной пользовательской сессии.\n",
    "* `1` - Пользователь купил продукт во время этой пользовательской сессии.\n",
    "\n",
    "Таким образом, мы можем легко рассчитать среднее значение для каждой группы, чтобы получить коэффициент конверсии для каждого дизайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор размера выборки\n",
    "\n",
    "Важно отметить, что поскольку мы не будем тестировать всю пользовательскую базу (наша генеральная совокупность), коэффициенты конверсии, которые мы получим, неизбежно будут только *оценками* истинных коэффициентов.\n",
    "\n",
    "Количество людей (или пользовательских сеансов), которые мы решим включить в каждую группу, повлияет на точность наших оценочных коэффициентов конверсии: **чем больше размер выборки**, тем точнее наши оценки (интервалы), **тем выше шанс обнаружить разницу** в двух группах, если она присутствует.\n",
    "\n",
    "С другой стороны, чем больше становится наша выборка, тем дороже (и непрактичнее) становится наше исследование.\n",
    "\n",
    "Так сколько человек должно быть в каждой группе?\n",
    "\n",
    "Необходимый нам размер выборки оценивается с помощью так называемого анализа мощности, и это зависит от нескольких факторов:\n",
    "* **Мощность теста** ($1 - \\beta$) - это вероятность обнаружения статистической разницы между группами в нашем тесте, когда разница действительно присутствует. Как правило, это значение равно 0,8 (если вам интересно, вот дополнительная информация о <a href=\"https://en.wikipedia.org/wiki/Power_of_a_test\">статистической мощности</a>)\n",
    "* **Альфа-значение** ($\\alpha$) — критическое значение, которое мы установили ранее равным 0,05.\n",
    "* **Величина эффекта** – ожидаемая разница между коэффициентами конверсии.\n",
    "\n",
    "Поскольку нашу команду устроила бы разница в $2\\%$, мы можем использовать $13\\%$ и $15\\%$ для расчета ожидаемой величины эффекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "font = {'family' : 'Helvetica',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=0.13\n",
    "p2=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "za = 1.96\n",
    "zb = 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_n = ceil(((za + zb)**2)*(p1*(1-p1)+p2*(1-p2))/((p1-p2)**2))\n",
    "required_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам потребуется **не менее 4716 наблюдений для каждой группы**.\n",
    "\n",
    "Установка параметра «мощность» на 0,8 на практике означает, что если существует фактическая разница в коэффициенте конверсии между нашими дизайнами, при условии, что разница является той, которую мы оценили (13% против 15%), у нас есть около 80% шансов на успех. обнаружить его как статистически значимое в нашем тесте с рассчитанным нами размером выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['group'], df['landing_page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть **294478 строк**, каждая из которых представляет сеанс пользователя, а также **5 столбцов**:\n",
    "* `user_id` - идентификатор пользователя каждой сессии\n",
    "* `timestamp` - Отметка времени сеанса\n",
    "* `group` — к какой группе был отнесен пользователь для этого сеанса {`control`, `treatment`}\n",
    "* `landing_page` — какой дизайн видел каждый пользователь в этом сеансе {`old_page`, `new_page`}\n",
    "* `converted` - закончился ли сеанс конверсией или нет (двоичный, `0`=не преобразовано, `1`=конвертировано)\n",
    "\n",
    "На самом деле мы будем использовать для анализа только столбцы «group» и «converted».\n",
    "\n",
    "Прежде чем мы приступим к выборке данных для получения нашего подмножества, давайте удостоверимся, что нет пользователей, которые были отобраны несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_counts = df['user_id'].value_counts(ascending=False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "\n",
    "print(f'В нашем наборе данных присутствует {multi_users} повторений пользователей по ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_drop = session_counts[session_counts > 1].index\n",
    "\n",
    "df = df[~df['user_id'].isin(users_to_drop)]\n",
    "print(f'После очистки имеем {df.shape[0]} записей')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sample = df[df['group'] == 'control'].sample(n=required_n, random_state=22)\n",
    "treatment_sample = df[df['group'] == 'treatment'].sample(n=required_n, random_state=22)\n",
    "\n",
    "ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test['group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates = ab_test.groupby('group')['converted']\n",
    "\n",
    "std_p = lambda x: np.std(x, ddof=0)              \n",
    "se_p = lambda x: stats.sem(x, ddof=0)            # (std / sqrt(n))\n",
    "\n",
    "conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])\n",
    "conversion_rates.columns = ['конверсия', 'сред. кв. отклонение', 'ошибка среднего']\n",
    "\n",
    "\n",
    "conversion_rates.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по приведенной выше статистике, похоже, что **наши два проекта работали очень похоже**, а наш новый дизайн работал немного лучше - **коэффициент конверсии 12,3% против 12,6%**.\n",
    "\n",
    "Визуализация данных облегчит понимание этих результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.barplot(x=ab_test['group'], y=ab_test['converted'], ci=False)\n",
    "\n",
    "plt.ylim(0, 0.17)\n",
    "plt.title('Конверсия по группам', pad=20)\n",
    "plt.xlabel('Группа', labelpad=15)\n",
    "plt.ylabel('Конверсия (пропорция)', labelpad=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты конверсии для наших групп действительно очень близки. Также обратите внимание, что коэффициент конверсии «контрольной» группы ниже, чем мы ожидали, учитывая то, что мы знали о нашем среднем значении. коэффициент конверсии (12,3% против 13%). Это говорит о том, что при выборке из ГС есть некоторые различия в результатах.\n",
    "\n",
    "Ценность экспериментальной группы выше. **Является ли эта разница *статистически значимой***?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Проверка гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последним шагом нашего анализа является проверка нашей гипотезы. Так как у нас очень большая выборка, мы можем использовать <a href=\"https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Normal_ приблизительно_interval\">нормальное приближение</a> для расчета нашего значения $p$ (т.е. z-тест).\n",
    "\n",
    "Опять же, Python делает все вычисления очень простыми. Мы можем использовать модуль `statsmodels.stats.proportion`, чтобы получить значение $p$ и доверительные интервалы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_results = ab_test[ab_test['group'] == 'control']['converted']\n",
    "treatment_results = ab_test[ab_test['group'] == 'treatment']['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_con = control_results.count()\n",
    "n_treat = treatment_results.count()\n",
    "successes = [control_results.sum(), treatment_results.sum()]\n",
    "nobs = [n_con, n_treat]\n",
    "\n",
    "z_stat, pval = proportions_ztest(successes, nobs=nobs)\n",
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n",
    "\n",
    "print(f'z-статистика: {z_stat:.2f}')\n",
    "print(f'p-value: {pval:.3f}')\n",
    "print(f'ДИ 95% для контрольной группы: [{lower_con:.3f}, {upper_con:.3f}]')\n",
    "print(f'ДИ 95% для тестовой группы: [{lower_treat:.3f}, {upper_treat:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наше значение $p=0.755$ намного превышает наше значение $\\alpha=0.05$, мы не можем отвергнуть нулевую гипотезу $H_0$, а это означает, что наш новый дизайн не имел существенных отличий (не говоря уже о лучшем) от нашего старого. :(\n",
    "\n",
    "Кроме того, если мы посмотрим на доверительный интервал для тестовой группы ( [0.116, 0.135], то есть 11,6-13,5%), то заметим, что:\n",
    "1. Он включает наше базовое значение коэффициента конверсии $13\\%$.\n",
    "2. Он не включает наше целевое значение в $15\\%$ ($2\\%$ роста, к которому мы стремились).\n",
    "\n",
    "Это означает, что более вероятно, что истинный коэффициент конверсии нового дизайна будет похож на наш базовый уровень, а не на целевые 15%, на которые мы надеялись. Это еще одно доказательство того, что наш новый дизайн вряд ли будет улучшением нашего старого дизайна!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Еще один пример проведения A/B теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cookie Cats - чрезвычайно популярная мобильная игра-головоломка, разработанная Tactile Entertainment. Это классическая игра-головоломка в стиле «соедините три», в которой игрок должен соединять плитки одного цвета, чтобы очистить поле и выиграть уровень. Здесь также есть поющие кошки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://i.ytimg.com/vi/iPxZIp0cbJE/maxresdefault.jpg\"  width=500></p>\n",
    " \n",
    " \n",
    "<p style=\"align: center;\"><img align=center src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_184/img/cc_gates.png\"  width=500></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере прохождения уровней игры игроки время от времени сталкиваются с воротами, которые заставляют их ждать некоторое количество времени или совершать покупки в приложении, чтобы продолжить. Помимо стимулирования покупок в приложении, эти ворота служат важной цели - дать игрокам вынужденный перерыв в игре, что, как мы надеемся, приведет к увеличению и продлению удовольствия от игры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Но где ставить ворота? </b>\n",
    "Первоначально первые ворота были размещены на уровне 30. В этом проекте вам предлагается проанализировать AB-тест, в котором создатели переместили первые ворота в Cookie Cats с 30 уровня на уровень 40. В частности, вам надо рассмотрим влияние A/B теста на удержание игроков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные A/B тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:16.121587Z",
     "start_time": "2022-03-01T11:32:16.031531Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cookie_cats.csv', on_bad_lines='skip')  # Откроем датасет\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данные получены от 90 189 игроков, которые установили игру во время проведения AB-теста. Переменные:**\n",
    "\n",
    "* `userid` - уникальный номер, идентифицирующий каждого игрока.\n",
    "\n",
    "* `version` - был ли игрок помещен в контрольную группу (gate_30 - ворота на уровне 30) или в тестовую группу (gate_40 - ворота на уровне 40).\n",
    "\n",
    "* `sum_gamerounds` - количество игровых раундов, сыгранных игроком в течение первой недели после установки\n",
    "* `retention_1` - проигрыватель вернулся и поиграл через 1 день после установки?\n",
    "* `retention_7` - проигрыватель вернулся и играл через 7 дней после установки?\n",
    "\n",
    "Когда игрок устанавливал игру, ему случайным образом назначали `gate_30` или `gate_40`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Задание: провести анализ данных и сделать выводы о лучшем месте для установки ворот.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:16.153569Z",
     "start_time": "2022-03-01T11:32:16.125537Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посмотрим на количество участников теста.\n",
    "data.groupby('version').version.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:16.201531Z",
     "start_time": "2022-03-01T11:32:16.157530Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby('version').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:16.265528Z",
     "start_time": "2022-03-01T11:32:16.203529Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby('version').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:17.067526Z",
     "start_time": "2022-03-01T11:32:16.283526Z"
    }
   },
   "outputs": [],
   "source": [
    "v_30 = data.loc[data.version == 'gate_30']\n",
    "v_40 = data.loc[data.version == 'gate_40']\n",
    "v_30 = v_30.drop(v_30.loc[v_30.sum_gamerounds > 200].index)\n",
    "v_40 = v_40.drop(v_40.loc[v_40.sum_gamerounds > 200].index)\n",
    "\n",
    "\n",
    "bins = 200\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(v_30['sum_gamerounds'], bins=bins, alpha=1,\n",
    "         edgecolor='black', label='gate 30')\n",
    "plt.hist(v_40['sum_gamerounds'], bins=bins, alpha=0.7, label='gate 40')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.45, 0.35))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:17.665527Z",
     "start_time": "2022-03-01T11:32:17.085537Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data.loc[data['sum_gamerounds'] < 100].copy();\n",
    "\n",
    "sns.catplot(x=\"version\", y=\"sum_gamerounds\",\n",
    "            hue=\"retention_1\", col = 'retention_7',\n",
    "            data=df, kind=\"box\",\n",
    "            height=5, aspect=.95);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие тесты мы знаем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:17.726536Z",
     "start_time": "2022-03-01T11:32:17.668527Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import mannwhitneyu\n",
    "import scipy.stats as stats\n",
    "\n",
    "stat, p = mannwhitneyu(data[data['version'] == 'gate_30']['sum_gamerounds'], data[data['version'] == 'gate_40']['sum_gamerounds'])\n",
    "\n",
    "print('Статистика=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Не отклоняем нулевую гипотезу, распределения, вероятно, одинаковые')\n",
    "else:\n",
    "    print('Отклоняем нулевую гипотезу, распределения, вероятно, различаются')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем Bootstrap для того, чтобы более наглядно убедиться в наличии различий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T11:32:32.977525Z",
     "start_time": "2022-03-01T11:32:17.746530Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "# boot_1d - собираем статистику по средним, для неё можно применить t-тест\n",
    "boot_1d = []\n",
    "for i in range(1000):\n",
    "    boot_mean = data.sample(frac=1, replace=True).groupby(\n",
    "        'version')['retention_7'].mean()  # retention_1\n",
    "    boot_1d.append(boot_mean)\n",
    "\n",
    "# Преобразование списка в DataFrame\n",
    "boot_1d = pd.DataFrame(boot_1d)\n",
    "\n",
    "# График полученного распределения\n",
    "boot_1d.plot(kind='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем использовать t-тест, необходимо проверить равенство дисперссий. Сделаем это с помощью <a href=\"https://ru.wikipedia.org/wiki/F-%D1%82%D0%B5%D1%81%D1%82\">F-теста</a>. Используем собстенную функцию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_test(group1, group2):\n",
    "    f = np.var(group1, ddof=1)/np.var(group2, ddof=1)\n",
    "    nun = group1.size-1\n",
    "    dun = group2.size-1\n",
    "    p_value = 1-st.f.cdf(f, nun, dun)\n",
    "    return f, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = f_test(boot_1d['gate_30'], boot_1d['gate_40'])\n",
    "\n",
    "print('Статистика=%.3f, p=%.5f' % (stat, p))\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Не отклоняем нулевую гипотезу, дисперссии, вероятно, одинаковые')\n",
    "else:\n",
    "    print('Отклоняем нулевую гипотезу, дисперссии, вероятно, различаются')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно использовать t-критерий Стьюдента!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = st.ttest_ind(boot_1d['gate_30'], boot_1d['gate_40'])\n",
    "print('Статистика=%.3f, p=%.10f' % (stat, p))\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Не отклоняем нулевую гипотезу, средние, вероятно, одинаковые')\n",
    "else:\n",
    "    print('Отклоняем нулевую гипотезу, средние, вероятно, различаются')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Выводы.</b> Наше значение $p$ близко к нулю, поэтому мы отвергаем нулевую гипотезу о том, что средние значения двух выборок одинаковые. То есть существует статистически значимая разница между тем где поставить ворота!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
