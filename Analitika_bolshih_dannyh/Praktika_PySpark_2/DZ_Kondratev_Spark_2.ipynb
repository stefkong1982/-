{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefkong1982/netology.ru/blob/Master/Analitika_bolshih_dannyh/Praktika_PySpark_2/DZ_Kondratev_Spark_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Домашнее задание «Практика PySpark (часть 2)»\n",
        "\n",
        "**Преподаватель:** Алексей Кузьмин\n",
        "\n",
        "Обучите модель классификации для цветков Iris.\n",
        "Примерная последовательность действий:\n",
        "\n",
        "1. [Взять данные.](https://drive.google.com/file/d/18ksAxTxBkp15LToEg46BHhwp3sPIoeUU/view?usp=sharing![изображение_2024-02-08_151549849.png](data:image/png;base64,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![изображение_2024-02-08_151610360.png](data:image/png;base64,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)))\n",
        "2. Загрузить в PySpark.\n",
        "3. При помощи VectorAssembler преобразовать все колонки с признаками в одну (использовать Pipeline — опционально).\n",
        "4. Разбить данные на train и test.\n",
        "5. Создать модель логистической регреcсии или модель дерева и обучить её.\n",
        "6. Воспользоваться MulticlassClassificationEvaluator для оценки качества на train и test множестве."
      ],
      "metadata": {
        "id": "ZXHGm7bul18a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkjqeMDxpo-a"
      },
      "source": [
        "Установка Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etFJ7ZgKpl41",
        "outputId": "6d444897-6ec9-4cd3-c0a6-89c4c8694b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Обновляем пакеты системы с помощью apt-get update\n",
        "!apt-get update"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,334 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 1,563 kB in 2s (833 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0HaFRkEps1B"
      },
      "source": [
        "# Устанавливаем OpenJDK 8 с помощью apt-get install.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy_sIJ6ypyIv"
      },
      "source": [
        "# Скачиваем архив Spark с официального сайта с помощью wget.\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q5LMILepz_N",
        "outputId": "44ac9ea0-ff02-4ef9-a21e-b43dcd29fd04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Распаковываем архив Spark с помощью tar -xvf.\n",
        "!tar -xvf spark-3.5.0-bin-hadoop3.tgz"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.5.0-bin-hadoop3/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.5.0-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.5.0-bin-hadoop3/NOTICE\n",
            "spark-3.5.0-bin-hadoop3/R/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.5.0-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.5.0-bin-hadoop3/python/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.5.0-bin-hadoop3/python/run-tests.py\n",
            "spark-3.5.0-bin-hadoop3/python/test_coverage/\n",
            "spark-3.5.0-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.5.0-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.5.0-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.5.0-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.5.0-bin-hadoop3/python/setup.cfg\n",
            "spark-3.5.0-bin-hadoop3/python/dist/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_classification.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_classification.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_summarizer.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_summarizer.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_distributor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_data_loader.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_tuning.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_tuning.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_function.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_nested.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_basic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_nested.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tuning.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_basic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_dl_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/tuning.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/classification.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/io_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/summarizer.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/connect/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/tests/test_data_loader.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/deepspeed/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/deepspeed/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/deepspeed/tests/test_deepspeed_distributor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/deepspeed/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/deepspeed/deepspeed_distributor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/dl_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/worker_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_apply_func.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_head_tail.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_split_apply.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_aggregate.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_describe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_arithmetic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_reverse.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_combine.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_apply_func.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_pivot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_any_all.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_binary_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_describe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_corrwith.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_compute.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cov.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_eval.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/computation/test_melt.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_arg_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_of.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_all_any.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_compute.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_sort.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_type.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_frame_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_resample.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_internal.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_matplotlib.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_matplotlib.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_plotly.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_plotly.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_apply_func.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_split_apply.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_describe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_aggregate.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_head_tail.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_reverse.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_boolean_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_arithmetic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_udt_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_string_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_categorical_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_null_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_binary_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/testing_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_date_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_complex_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_datetime_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_timedelta_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_apply_func.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_compute.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_melt.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_combine.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_pivot.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_describe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_binary_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_corrwith.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_any_all.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_eval.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cov.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_categorical.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ewm.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_repr.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_all_any.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_compute.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_of.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_missing_data.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_arg_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_stat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_sort.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_cumulative.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_type.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_extension.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_reshape.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_config.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_numpy_compat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_spark_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reindexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_attrs.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_take.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_constructor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reshaping.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_truncate.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_time_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_namespace.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_typedef.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_sql.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/io/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/io/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/io/test_parity_io.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_default_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_rolling.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexops_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_scalars.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_stats.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_generic_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reindex.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_timedelta.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_rename.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_indexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reset_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_category.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_align.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_datetime.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_datetime.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_string.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_csv.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_expanding.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_spark_io.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_cov_corrwith.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_basic_slow.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_align.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_time_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_constructor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reshaping.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_attrs.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_take.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_truncate.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reindexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/io/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/io/test_io.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/io/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_indexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_align.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reset_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reindex.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_rename.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_align.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_index.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_basic_slow.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_cov_corrwith.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach_batch.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_session.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_scalar.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_python_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_streaming.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_listener.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udtf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_grouped_agg.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map_with_state.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/client/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_artifact.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/client/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_client.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_udtf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/udtf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/protobuf/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/protobuf/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/protobuf/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/udtf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/readwriter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/query.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/foreach_batch_worker.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/listener_worker.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/client/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/client/core.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/client/artifact.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/client/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/client/reattach.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/avro/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/avro/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/avro/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.5.0-bin-hadoop3/python/mypy.ini\n",
            "spark-3.5.0-bin-hadoop3/python/README.md\n",
            "spark-3.5.0-bin-hadoop3/python/run-tests\n",
            "spark-3.5.0-bin-hadoop3/python/lib/\n",
            "spark-3.5.0-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.5.0-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.5.0-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.5.0-bin-hadoop3/python/.coveragerc\n",
            "spark-3.5.0-bin-hadoop3/python/.gitignore\n",
            "spark-3.5.0-bin-hadoop3/python/setup.py\n",
            "spark-3.5.0-bin-hadoop3/python/docs/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/user_guide/sql/python_udtf.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/udtf.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.testing.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/testing_pyspark.ipynb\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/errors.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.5.0-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.5.0-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.5.0-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.5.0-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.5.0-bin-hadoop3/examples/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/udtf.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.5.0-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.5.0-bin-hadoop3/examples/jars/\n",
            "spark-3.5.0-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.5.0-bin-hadoop3/examples/jars/spark-examples_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/README.md\n",
            "spark-3.5.0-bin-hadoop3/sbin/\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.5.0-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.5.0-bin-hadoop3/yarn/\n",
            "spark-3.5.0-bin-hadoop3/yarn/spark-3.5.0-yarn-shuffle.jar\n",
            "spark-3.5.0-bin-hadoop3/RELEASE\n",
            "spark-3.5.0-bin-hadoop3/licenses/\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.5.0-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.5.0-bin-hadoop3/data/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/als/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.5.0-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.5.0-bin-hadoop3/data/streaming/\n",
            "spark-3.5.0-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.5.0-bin-hadoop3/data/graphx/\n",
            "spark-3.5.0-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.5.0-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/junitLargeJar.jar\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/crc/\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/crc/smallJar.txt\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/crc/README.md\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/crc/junitLargeJar.txt\n",
            "spark-3.5.0-bin-hadoop3/data/artifact-tests/smallJar.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-resource-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-hk2-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-buffer-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jcl-over-slf4j-2.0.7.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/avro-ipc-1.11.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-core-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arrow-format-12.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-kubernetes_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arrow-memory-core-12.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/orc-mapreduce-1.9.1-shaded-protobuf.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/zstd-jni-1.5.5-4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/javassist-3.29.2-GA.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-kvstore_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-core-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-network-common_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-client-api-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-jackson-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-reflect-2.12.18.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/avro-1.11.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-catalyst_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/snappy-java-1.1.10.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/joda-time-2.12.5.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-compress-1.23.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-container-servlet-core-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/snakeyaml-2.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-column-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-io-2.13.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-common-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-handler-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-policy-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-mllib_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/tink-1.9.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-discovery-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/metrics-graphite-4.2.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arrow-vector-12.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-apps-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/RoaringBitmap-0.9.45.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-coordination-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-compiler-2.12.18.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-certificates-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jul-to-slf4j-2.0.7.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/shims-0.9.45.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/metrics-json-4.2.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-resolver-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-launcher_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-sketch_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-hive_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-scheduling-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-rbac-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-library-2.12.18.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-networking-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-databind-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-annotations-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-format-structures-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/xbean-asm9-shaded-4.23.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-encoding-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-server-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-sql-api_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-sql_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/datasketches-memory-2.1.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/datasketches-java-3.3.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-extensions-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/okio-1.15.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-parser-combinators_2.12-2.3.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arrow-memory-netty-12.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-all-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/metrics-jmx-4.2.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-container-servlet-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/avro-mapred-1.11.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-core_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-hadoop-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-module-scala_2.12-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-codec-http-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/snakeyaml-engine-2.6.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-repl_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-graphx_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-network-shuffle_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-codec-1.16.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-tags_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/log4j-slf4j2-impl-2.20.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-client-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-mesos_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/slf4j-api-2.0.7.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-streaming_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-codec-socks-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-unsafe_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/orc-shims-1.9.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-common-utils_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-handler-proxy-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-node-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/log4j-api-2.20.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jersey-common-2.40.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/objenesis-3.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/metrics-jvm-4.2.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-datatype-jsr310-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-mllib-local_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-events-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-metrics-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/log4j-1.2-api-2.20.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/orc-core-1.9.1-shaded-protobuf.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-dataformat-yaml-2.15.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/log4j-core-2.20.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/metrics-core-4.2.19.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/parquet-common-1.13.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-batch-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-common-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/aircompressor-0.25.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-codec-http2-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spark-yarn_2.12-3.5.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/netty-codec-4.1.96.Final.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-apiextensions-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/rocksdbjni-8.3.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-storageclass-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-model-autoscaling-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/jars/kubernetes-client-6.7.2.jar\n",
            "spark-3.5.0-bin-hadoop3/conf/\n",
            "spark-3.5.0-bin-hadoop3/conf/workers.template\n",
            "spark-3.5.0-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.5.0-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.5.0-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.5.0-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.5.0-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.5.0-bin-hadoop3/LICENSE\n",
            "spark-3.5.0-bin-hadoop3/bin/\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-sql\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-submit\n",
            "spark-3.5.0-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/beeline\n",
            "spark-3.5.0-bin-hadoop3/bin/pyspark\n",
            "spark-3.5.0-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.5.0-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/run-example\n",
            "spark-3.5.0-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/sparkR\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-class\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.5.0-bin-hadoop3/bin/spark-shell\n",
            "spark-3.5.0-bin-hadoop3/bin/find-spark-home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiQOFODip19a"
      },
      "source": [
        "# Устанавливаем findspark с помощью pip install.\n",
        "!pip install -q findspark"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJCFdpyJp4Oe"
      },
      "source": [
        "# Устанавливаем переменные окружения JAVA_HOME и SPARK_HOME для работы с Spark.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.2-bin-hadoop3\""
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем findspark для работы с Spark.\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Создаем экземпляр SparkSession для работы с Spark.\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Получаем контекст SparkContext для работы с Spark.\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "iRGY9sdmFNp1"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузите данные при помощи spark.read.csv из приложенного файла"
      ],
      "metadata": {
        "id": "7YHTh16z4k8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Набор данных растений ириса\n",
        "\n",
        "\n",
        "**Характеристики набора данных:**\n",
        "\n",
        "    :Количество экземпляров: 150 (по 50 в каждом из трёх классов)\n",
        "    :Количество атрибутов: 4 числовых, прогнозируемых атрибута и класс.\n",
        "    :Информация об атрибутах:\n",
        "        - sepal length - длина чашелистика в см\n",
        "        - sepal width - ширина чашелистика в см\n",
        "        - petal length - длина лепестка в см\n",
        "        - petal width - ширина лепестка в см\n",
        "        - Класс:\n",
        "                - 0-Setosa\n",
        "                - 1-Versicolour\n",
        "                - 2-Virginica\n"
      ],
      "metadata": {
        "id": "p7sJnZq8lcML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных: Данные загружаются из файла 'iris.CSV' в датафрейм Spark\n",
        "# с помощью метода read.csv(). Параметры inferSchema=True и header=True\n",
        "# используются для автоматического определения схемы данных и загрузки заголовка CSV-файла соответственно.\n",
        "\n",
        "df = spark.read.csv('iris.CSV', inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "cZwqcNJLvwsq"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Отображаем первые 5 строк датафрейма.\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "sj0Mbw4G090m",
        "outputId": "1dbc1495-3240-4b4c-d5c1-10182e96d328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+-----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|\n",
            "+------------+-----------+------------+-----------+-------+-----------+\n",
            "|         5.1|        3.5|         1.4|        0.2| Setosa|          0|\n",
            "|         4.9|        3.0|         1.4|        0.2| Setosa|          0|\n",
            "|         4.7|        3.2|         1.3|        0.2| Setosa|          0|\n",
            "|         4.6|        3.1|         1.5|        0.2| Setosa|          0|\n",
            "|         5.0|        3.6|         1.4|        0.2| Setosa|          0|\n",
            "+------------+-----------+------------+-----------+-------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### При помощи VectorAssembler преобразовать все колонки с признаками в одну (использовать Pipeline — опционально).\n"
      ],
      "metadata": {
        "id": "klvlesUK40lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# В данном коде мы импортируем модули Vectors и VectorAssembler из PySpark.\n",
        "# Модуль Vectors содержит классы и функции для работы с векторами признаков,\n",
        "# а модуль VectorAssembler используется для сборки признаков в вектор."
      ],
      "metadata": {
        "id": "RY-XVXr74_YO"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метод df.columns возвращает список столбцов датафрейма df.\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "id": "whLkOZiPy4HW",
        "outputId": "d86e4afd-1cad-4f36-9046-8c1b594d2848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal_length',\n",
              " 'sepal_width',\n",
              " 'petal_length',\n",
              " 'petal_width',\n",
              " 'variety',\n",
              " 'variety_num']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование признаков:\n",
        "# Функция VectorAssembler используется для преобразования признаков\n",
        "# 'sepal_length', 'sepal_width', 'petal_length', 'petal_width' в вектор признаков 'Features'.\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\n",
        " 'sepal_length',\n",
        " 'sepal_width',\n",
        " 'petal_length',\n",
        " 'petal_width',\n",
        " ], outputCol='Features')"
      ],
      "metadata": {
        "id": "RFxDtGc50DCF"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = assembler.transform(df)\n",
        "\n",
        "# В данном коде мы применяем функцию VectorAssembler к датафрейму df с помощью метода transform().\n",
        "# Метод transform() применяет функцию к каждому ряду датафрейма и возвращает новый датафрейм с преобразованными данными.\n",
        "# В результате применения VectorAssembler к df, мы получаем новый датафрейм, в котором все признаки\n",
        "# 'sepal_length', 'sepal_width', 'petal_length', 'petal_width' объединены в один столбец 'Features'."
      ],
      "metadata": {
        "id": "nQ2BJJ0p1tGW"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "T0KnF8rP0j21",
        "outputId": "4d175fff-40a4-428d-e7f4-daae5b837448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|         Features|\n",
            "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
            "|         5.1|        3.5|         1.4|        0.2| Setosa|          0|[5.1,3.5,1.4,0.2]|\n",
            "|         4.9|        3.0|         1.4|        0.2| Setosa|          0|[4.9,3.0,1.4,0.2]|\n",
            "|         4.7|        3.2|         1.3|        0.2| Setosa|          0|[4.7,3.2,1.3,0.2]|\n",
            "|         4.6|        3.1|         1.5|        0.2| Setosa|          0|[4.6,3.1,1.5,0.2]|\n",
            "|         5.0|        3.6|         1.4|        0.2| Setosa|          0|[5.0,3.6,1.4,0.2]|\n",
            "|         5.4|        3.9|         1.7|        0.4| Setosa|          0|[5.4,3.9,1.7,0.4]|\n",
            "|         4.6|        3.4|         1.4|        0.3| Setosa|          0|[4.6,3.4,1.4,0.3]|\n",
            "|         5.0|        3.4|         1.5|        0.2| Setosa|          0|[5.0,3.4,1.5,0.2]|\n",
            "|         4.4|        2.9|         1.4|        0.2| Setosa|          0|[4.4,2.9,1.4,0.2]|\n",
            "|         4.9|        3.1|         1.5|        0.1| Setosa|          0|[4.9,3.1,1.5,0.1]|\n",
            "|         5.4|        3.7|         1.5|        0.2| Setosa|          0|[5.4,3.7,1.5,0.2]|\n",
            "|         4.8|        3.4|         1.6|        0.2| Setosa|          0|[4.8,3.4,1.6,0.2]|\n",
            "|         4.8|        3.0|         1.4|        0.1| Setosa|          0|[4.8,3.0,1.4,0.1]|\n",
            "|         4.3|        3.0|         1.1|        0.1| Setosa|          0|[4.3,3.0,1.1,0.1]|\n",
            "|         5.8|        4.0|         1.2|        0.2| Setosa|          0|[5.8,4.0,1.2,0.2]|\n",
            "|         5.7|        4.4|         1.5|        0.4| Setosa|          0|[5.7,4.4,1.5,0.4]|\n",
            "|         5.4|        3.9|         1.3|        0.4| Setosa|          0|[5.4,3.9,1.3,0.4]|\n",
            "|         5.1|        3.5|         1.4|        0.3| Setosa|          0|[5.1,3.5,1.4,0.3]|\n",
            "|         5.7|        3.8|         1.7|        0.3| Setosa|          0|[5.7,3.8,1.7,0.3]|\n",
            "|         5.1|        3.8|         1.5|        0.3| Setosa|          0|[5.1,3.8,1.5,0.3]|\n",
            "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разобьем данные на данные для обучения и проверки"
      ],
      "metadata": {
        "id": "SJU8qQVaWv7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df.randomSplit([0.8, 0.2], seed=12345)\n",
        "\n",
        "# Разбиение данных на обучающую и тестовую выборки:\n",
        "# Метод randomSplit() используется для случайного разделения датафрейма\n",
        "# на обучающую и тестовую выборки с заданными пропорциями.\n",
        "\n",
        "#В данном случае, 80% данных используется для обучения, а 20% - для тестирования.\n",
        "\n",
        "# Параметр seed=12345 в методе randomSplit()\n",
        "# используется для задания начального значения генератора случайных чисел.\n",
        "\n",
        "# Это позволяет получить воспроизводимые результаты разделения данных на обучающую и тестовую выборки.\n",
        "# Если вы используете один и тот же код и зададите тот же seed, то получите одни и те же случайные числа,\n",
        "# и, следовательно, одни и те же обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "NO4HzbICT8kv"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.show()"
      ],
      "metadata": {
        "id": "6UiPxGbLpQmW",
        "outputId": "04c2b112-618f-4795-f713-e3ca12cf3a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|   variety|variety_num|         Features|\n",
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+\n",
            "|         4.3|        3.0|         1.1|        0.1|    Setosa|          0|[4.3,3.0,1.1,0.1]|\n",
            "|         4.4|        2.9|         1.4|        0.2|    Setosa|          0|[4.4,2.9,1.4,0.2]|\n",
            "|         4.4|        3.0|         1.3|        0.2|    Setosa|          0|[4.4,3.0,1.3,0.2]|\n",
            "|         4.4|        3.2|         1.3|        0.2|    Setosa|          0|[4.4,3.2,1.3,0.2]|\n",
            "|         4.5|        2.3|         1.3|        0.3|    Setosa|          0|[4.5,2.3,1.3,0.3]|\n",
            "|         4.6|        3.1|         1.5|        0.2|    Setosa|          0|[4.6,3.1,1.5,0.2]|\n",
            "|         4.6|        3.4|         1.4|        0.3|    Setosa|          0|[4.6,3.4,1.4,0.3]|\n",
            "|         4.6|        3.6|         1.0|        0.2|    Setosa|          0|[4.6,3.6,1.0,0.2]|\n",
            "|         4.7|        3.2|         1.3|        0.2|    Setosa|          0|[4.7,3.2,1.3,0.2]|\n",
            "|         4.7|        3.2|         1.6|        0.2|    Setosa|          0|[4.7,3.2,1.6,0.2]|\n",
            "|         4.8|        3.0|         1.4|        0.1|    Setosa|          0|[4.8,3.0,1.4,0.1]|\n",
            "|         4.8|        3.0|         1.4|        0.3|    Setosa|          0|[4.8,3.0,1.4,0.3]|\n",
            "|         4.8|        3.1|         1.6|        0.2|    Setosa|          0|[4.8,3.1,1.6,0.2]|\n",
            "|         4.8|        3.4|         1.6|        0.2|    Setosa|          0|[4.8,3.4,1.6,0.2]|\n",
            "|         4.8|        3.4|         1.9|        0.2|    Setosa|          0|[4.8,3.4,1.9,0.2]|\n",
            "|         4.9|        2.4|         3.3|        1.0|Versicolor|          1|[4.9,2.4,3.3,1.0]|\n",
            "|         4.9|        2.5|         4.5|        1.7| Virginica|          2|[4.9,2.5,4.5,1.7]|\n",
            "|         4.9|        3.0|         1.4|        0.2|    Setosa|          0|[4.9,3.0,1.4,0.2]|\n",
            "|         4.9|        3.1|         1.5|        0.1|    Setosa|          0|[4.9,3.1,1.5,0.1]|\n",
            "|         4.9|        3.1|         1.5|        0.2|    Setosa|          0|[4.9,3.1,1.5,0.2]|\n",
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создадим и обучим модель логистической регрессии"
      ],
      "metadata": {
        "id": "lnJHcaSA5XPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# В данном коде мы импортируем класс LogisticRegression из модуля pyspark.ml.classification.\n",
        "# Класс LogisticRegression используется для обучения модели логистической регрессии."
      ],
      "metadata": {
        "id": "s0d9_QT8WlSH"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol = 'Features', labelCol = 'variety_num')\n",
        "lrModel = lr.fit(train)\n",
        "\n",
        "# Обучение модели логистической регрессии:\n",
        "# Создается экземпляр класса LogisticRegression\n",
        "# с указанием столбца признаков 'Features' и столбца меток 'variety_num'.\n",
        "\n",
        "# Затем модель обучается на обучающей выборке с помощью метода fit()."
      ],
      "metadata": {
        "id": "uvrsUBz92UzV"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_res = lrModel.transform(train)\n",
        "test_res = lrModel.transform(test)\n",
        "\n",
        "# В данном коде мы применяем обученную модель логистической регрессии lrModel\n",
        "# к обучающей выборке train и тестовой выборке test с помощью метода transform().\n",
        "\n",
        "# Метод transform() применяет модель к данным и возвращает новый датафрейм с предсказаниями модели.\n",
        "# В результате, мы получаем датафреймы train_res и test_res, которые содержат исходные данные и предсказания модели для каждой строки."
      ],
      "metadata": {
        "id": "lzpggDOp2rZj"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas = train_res.toPandas()\n",
        "df_pandas.head(1)\n",
        "\n",
        "# Данный код преобразует датафрейм train_res из PySpark в pandas.DataFrame с помощью метода toPandas().\n",
        "# Затем он выводит на экран первую строку преобразованного датафрейма с помощью метода head(1).\n",
        "# Этот код позволяет просмотреть первые несколько строк датафрейма train_res как полноценный датафрейм в pandas."
      ],
      "metadata": {
        "id": "77YLuvws2wbD",
        "outputId": "f37624ee-a5f0-4e32-c125-7060ee89a44a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width variety  variety_num  \\\n",
              "0           4.3          3.0           1.1          0.1  Setosa            0   \n",
              "\n",
              "               Features                                      rawPrediction  \\\n",
              "0  [4.3, 3.0, 1.1, 0.1]  [67.70279195875312, -5.483728693221446, -62.21...   \n",
              "\n",
              "                                         probability  prediction  \n",
              "0  [1.0, 1.642471835404166e-32, 3.764048385223648...         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b09c923-2b61-49e4-b4e0-8613a2fe1b4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>variety</th>\n",
              "      <th>variety_num</th>\n",
              "      <th>Features</th>\n",
              "      <th>rawPrediction</th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Setosa</td>\n",
              "      <td>0</td>\n",
              "      <td>[4.3, 3.0, 1.1, 0.1]</td>\n",
              "      <td>[67.70279195875312, -5.483728693221446, -62.21...</td>\n",
              "      <td>[1.0, 1.642471835404166e-32, 3.764048385223648...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b09c923-2b61-49e4-b4e0-8613a2fe1b4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b09c923-2b61-49e4-b4e0-8613a2fe1b4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b09c923-2b61-49e4-b4e0-8613a2fe1b4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Значения `rawPrediction` представляют собой скалярное произведение вектора признаков и вектора коэффициентов модели.\n",
        "\n",
        "* `67.70279195875312` - это предсказание модели для класса `Setosa`.\n",
        "\n",
        "* `-5.483728693221446` - это предсказание модели для класса `Versicolor`.\n",
        "\n",
        "* `-62.21906326553166` - это предсказание модели для класса `Virginica`.\n",
        "\n",
        "Чем больше это значение, тем больше вероятность того, что наблюдение принадлежит к соответствующему классу.\n",
        "\n",
        "\n",
        "2. Pначения `probability` представляют собой вероятности принадлежности каждого наблюдения к каждому из классов.\n",
        "\n",
        "* `1.0` - это вероятность принадлежности наблюдения к классу `Setosa`.\n",
        "\n",
        "* `1.642471835404166e-32` - это вероятность принадлежности наблюдения к классу `Versicolor`.\n",
        "\n",
        "\n",
        "* `3.764048385223648e-57` - это вероятность принадлежности наблюдения к классу `Virginica`.\n",
        "\n",
        "Это значение может быть интерпретировано как степень уверенности модели в принадлежности данного наблюдения к классу. Чем ближе значение к 1, тем больше вероятность того, что наблюдение принадлежит к соответствующему классу.\n",
        "\n",
        "3. `prediction` - это предсказанный класс для каждого наблюдения. В данном случае, наблюдение было предсказано как класс `Setosa`.\n",
        "\n"
      ],
      "metadata": {
        "id": "AIwcNxT3Jvpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оценим качество\n",
        "\n",
        "Для оценки качества предсказания в spark реализованно несколько классов\n",
        "\n",
        "Если мы решаем задачу бинарной классификации (то есть классов - 2),\n",
        "\n",
        "то нам подойдет `BinaryCLassificationEvaluator`,\n",
        "\n",
        "а если классов больше 2-х, то `MulticlassClassificationEvaluator`"
      ],
      "metadata": {
        "id": "-ttDlzuedZCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Библиотека pyspark.ml.evaluation содержит классы и функции\n",
        "# для оценки качества моделей машинного обучения в PySpark.\n",
        "\n",
        "# В данном случае, мы используем класс MulticlassClassificationEvaluator\n",
        "# для оценки качества модели логистической регрессии на основе метрики точности."
      ],
      "metadata": {
        "id": "_WJzd21g2v31"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ev = MulticlassClassificationEvaluator(labelCol='variety_num')\n",
        "\n",
        "# Оценка качества модели: Для оценки качества модели используется MulticlassClassificationEvaluator.\n",
        "# Создается экземпляр класса MulticlassClassificationEvaluator с указанием столбца меток 'variety_num'."
      ],
      "metadata": {
        "id": "TX3UVe-zgqRu"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метод evaluate() применяется к результатам обучения и тестирования модели. Значение точности выводится на экран.\n",
        "\n",
        "ev.evaluate(train_res)\n",
        "print(\"Точность модели на обучающей выборке: %.2f\" % ev.evaluate(train_res))\n",
        "\n",
        "ev.evaluate(test_res)\n",
        "print(\"Точность модели на тестовой выборке: %.2f\" % ev.evaluate(test_res))"
      ],
      "metadata": {
        "id": "tgtP-OIsYIT_",
        "outputId": "d9e393ff-2723-4364-ad59-97edfb9df1b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели на обучающей выборке: 0.98\n",
            "Точность модели на тестовой выборке: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучите модель дерева решений и оцените его качество\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oP6zkL66d2R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "S0QEv8VucaHJ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = DecisionTreeClassifier(featuresCol='Features', labelCol='variety_num')\n",
        "trFitted = tr.fit(train)\n",
        "\n",
        "# Обучение модели дерева решений:\n",
        "# Аналогично предыдущему шагу, создается экземпляр класса DecisionTreeClassifier\n",
        "# с указанием столбца признаков 'Features' и столбца меток 'variety_num'.\n",
        "# Затем модель обучается на обучающей выборке с помощью метода fit()."
      ],
      "metadata": {
        "id": "0t4jhIVj4oXH"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tr_res=trFitted.transform(train)\n",
        "test_tr_res=trFitted.transform(test)\n",
        "\n",
        "# В данном коде мы применяем обученную модель логистической регрессии lrModel\n",
        "# к обучающей выборке train и тестовой выборке test с помощью метода transform()."
      ],
      "metadata": {
        "id": "3Ir9Epj76btx"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tr_res.show()"
      ],
      "metadata": {
        "id": "4JSs8Dsk6b6m",
        "outputId": "5ca12ef6-6037-4948-e9d7-6a6a5c679029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+--------------+-------------+----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|   variety|variety_num|         Features| rawPrediction|  probability|prediction|\n",
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+--------------+-------------+----------+\n",
            "|         4.3|        3.0|         1.1|        0.1|    Setosa|          0|[4.3,3.0,1.1,0.1]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.4|        2.9|         1.4|        0.2|    Setosa|          0|[4.4,2.9,1.4,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.4|        3.0|         1.3|        0.2|    Setosa|          0|[4.4,3.0,1.3,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.4|        3.2|         1.3|        0.2|    Setosa|          0|[4.4,3.2,1.3,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.5|        2.3|         1.3|        0.3|    Setosa|          0|[4.5,2.3,1.3,0.3]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.6|        3.1|         1.5|        0.2|    Setosa|          0|[4.6,3.1,1.5,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.6|        3.4|         1.4|        0.3|    Setosa|          0|[4.6,3.4,1.4,0.3]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.6|        3.6|         1.0|        0.2|    Setosa|          0|[4.6,3.6,1.0,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.7|        3.2|         1.3|        0.2|    Setosa|          0|[4.7,3.2,1.3,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.7|        3.2|         1.6|        0.2|    Setosa|          0|[4.7,3.2,1.6,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.8|        3.0|         1.4|        0.1|    Setosa|          0|[4.8,3.0,1.4,0.1]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.8|        3.0|         1.4|        0.3|    Setosa|          0|[4.8,3.0,1.4,0.3]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.8|        3.1|         1.6|        0.2|    Setosa|          0|[4.8,3.1,1.6,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.8|        3.4|         1.6|        0.2|    Setosa|          0|[4.8,3.4,1.6,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.8|        3.4|         1.9|        0.2|    Setosa|          0|[4.8,3.4,1.9,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.9|        2.4|         3.3|        1.0|Versicolor|          1|[4.9,2.4,3.3,1.0]|[0.0,40.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
            "|         4.9|        2.5|         4.5|        1.7| Virginica|          2|[4.9,2.5,4.5,1.7]| [0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
            "|         4.9|        3.0|         1.4|        0.2|    Setosa|          0|[4.9,3.0,1.4,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.9|        3.1|         1.5|        0.1|    Setosa|          0|[4.9,3.1,1.5,0.1]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|         4.9|        3.1|         1.5|        0.2|    Setosa|          0|[4.9,3.1,1.5,0.2]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "+------------+-----------+------------+-----------+----------+-----------+-----------------+--------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Метод evaluate() применяется к результатам обучения и тестирования модели. Значение точности выводится на экран.\n",
        "\n",
        "ev.evaluate(train_tr_res)\n",
        "print(\"Точность модели дерева решений на обучающей выборке: %.2f\" % ev.evaluate(train_tr_res))\n",
        "\n",
        "ev.evaluate(test_tr_res)\n",
        "print(\"Точность модели дерева решений на тестовой выборке: %.2f\" % ev.evaluate(test_tr_res))"
      ],
      "metadata": {
        "id": "qpEN4bGg6hy2",
        "outputId": "c717b2ce-ecd5-45ce-91d2-a46486dd455b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели дерева решений на обучающей выборке: 0.99\n",
            "Точность модели дерева решений на тестовой выборке: 1.00\n"
          ]
        }
      ]
    }
  ]
}