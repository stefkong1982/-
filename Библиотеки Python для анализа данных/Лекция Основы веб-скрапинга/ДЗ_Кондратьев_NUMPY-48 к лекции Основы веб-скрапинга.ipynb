{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо написать функцию, которая будет основана на **поиске** по сайту [habr.com](https://habr.com/ru/search/).\n",
    "Функция в качестве параметра должна принимать **список** запросов для поиска (например, `['python', 'анализ данных']`) и на основе материалов, попавших в результаты поиска по **каждому** запросу, возвращать датафрейм вида:\n",
    "\n",
    "```\n",
    "<дата> - <заголовок> - <ссылка на материал>\n",
    "```\n",
    "\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '', 'title': 'Как я проектирую и разрабатываю расширения Python на Rust', 'link': 'https://habr.com/en/articles/767254/'}\n",
      "{'date': '', 'title': 'Функциональное программирование в Python: ежедневные рецепты', 'link': 'https://habr.com/en/companies/kaspersky/articles/762788/'}\n",
      "{'date': '', 'title': 'Многопоточность в Python: очевидное и невероятное', 'link': 'https://habr.com/en/articles/764420/'}\n",
      "{'date': '', 'title': '10 лучших практик логирования в Python', 'link': 'https://habr.com/en/companies/ruvds/articles/766010/'}\n",
      "{'date': '', 'title': 'Как работать с процессами и потоками в Python', 'link': 'https://habr.com/en/companies/simbirsoft/articles/701020/'}\n",
      "{'date': '', 'title': 'Построение пайплайна обработки данных в реальном времени с использованием Python', 'link': 'https://habr.com/en/companies/otus/articles/764136/'}\n",
      "{'date': '', 'title': 'Как настроить сбор статистики и автоматическое отключение пользователей WireGuard в ispmanager с помощью Python и API', 'link': 'https://habr.com/en/companies/ispmanager/articles/764290/'}\n",
      "{'date': '', 'title': 'Microsoft представила дополнение Python Editor от команды Excel Labs', 'link': 'https://habr.com/en/news/761862/'}\n",
      "{'date': '', 'title': 'Как правильно писать API авто тесты на Python', 'link': 'https://habr.com/en/articles/709380/'}\n",
      "{'date': '', 'title': 'FIFO очередь asyncio в Python', 'link': 'https://habr.com/en/articles/764932/'}\n",
      "{'date': '', 'title': 'Microsoft добавила Python в Excel', 'link': 'https://habr.com/en/news/756266/'}\n",
      "{'date': '', 'title': 'JetBrains и Python Software Foundation рассказали, как разработчики использовали Python в 2022 году', 'link': 'https://habr.com/en/news/766124/'}\n",
      "{'date': '', 'title': 'Вышел Python 2.7.18, последний релиз ветки Python 2.x', 'link': 'https://habr.com/en/news/498364/'}\n",
      "{'date': '', 'title': 'Год ожиданий — и мы получили Python 3.12. Изменения, новшества и дополнения', 'link': 'https://habr.com/en/companies/selectel/articles/761914/'}\n",
      "{'date': '', 'title': 'Три уровня погружения в Python. Запись докладов с Python Meetup и полезные материалы', 'link': 'https://habr.com/en/companies/selectel/news/766270/'}\n",
      "{'date': '', 'title': 'Полноценный 2D-платформер на Python в 2023? Мой опыт', 'link': 'https://habr.com/en/articles/766162/'}\n",
      "{'date': '', 'title': 'Python: Построение графиков по данным из файла', 'link': 'https://habr.com/en/articles/748282/'}\n",
      "{'date': '', 'title': 'Python как компилируемый статически типизированный язык программирования', 'link': 'https://habr.com/en/news/531402/'}\n",
      "{'date': '', 'title': 'В начале этого года Python сместил Java и стал вторым по популярности языком программирования среди разработчиков', 'link': 'https://habr.com/en/companies/itsumma/news/490834/'}\n",
      "{'date': '', 'title': 'Есть ли будущее у Python? Обсудим в этот четверг', 'link': 'https://habr.com/en/companies/selectel/news/763330/'}\n",
      "{'date': '', 'title': 'Пять лет Школе анализа данных', 'link': 'https://habr.com/en/companies/yandex/articles/148443/'}\n",
      "{'date': '', 'title': '10 лет Школе анализа данных Яндекса', 'link': 'https://habr.com/en/companies/yandex/articles/334066/'}\n",
      "{'date': '', 'title': 'Как за две недели проверить гипотезы применимости анализа данных в горно-металлургической компании', 'link': 'https://habr.com/en/companies/factory5/articles/681846/'}\n",
      "{'date': '', 'title': 'Что такое бессерверный SQL? И как использовать его для анализа данных?', 'link': 'https://habr.com/en/companies/microsoft/articles/537064/'}\n",
      "{'date': '', 'title': 'Как мы строим систему обработки, хранения и анализа данных в СИБУРе', 'link': 'https://habr.com/en/companies/sibur_official/articles/436632/'}\n",
      "{'date': '', 'title': 'Становясь Пангеей: будущее современного стека для анализа данных', 'link': 'https://habr.com/en/articles/763942/'}\n",
      "{'date': '', 'title': 'В\\xa0VK Cloud стал доступен инструмент поиска и анализа данных OpenSearch', 'link': 'https://habr.com/en/news/740666/'}\n",
      "{'date': '', 'title': 'Ubic создаст платформу для анализа данных о москвичах', 'link': 'https://habr.com/en/news/501944/'}\n",
      "{'date': '', 'title': 'Microsoft анонсировала запуск «Планетарного компьютера» для сбора, хранения и анализа данных о состоянии Земли', 'link': 'https://habr.com/en/news/497474/'}\n",
      "{'date': '', 'title': '', 'link': ''}\n",
      "{'date': '', 'title': 'Владимир Путин выступил с Германом Грефом на конференции по ИИ и анализу данных Artificial Intelligence Journey 2021', 'link': 'https://habr.com/en/news/588991/'}\n",
      "{'date': '', 'title': 'Интенсив для повышения квалификации: как использовать Python для анализа данных', 'link': 'https://habr.com/en/companies/netologyru/news/594683/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №3 (обзор онлайн курсов)', 'link': 'https://habr.com/en/articles/228187/'}\n",
      "{'date': '', 'title': 'Почему так много «липовых» специалистов по анализу данных?', 'link': 'https://habr.com/en/articles/298670/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №17 (6 — 12 октября 2014)', 'link': 'https://habr.com/en/articles/240139/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №1 (9 — 16 июня 2014)', 'link': 'https://habr.com/en/articles/226641/'}\n",
      "{'date': '', 'title': 'Использование Python и Excel для обработки и анализа данных. Часть 1: импорт данных и настройка среды', 'link': 'https://habr.com/en/companies/otus/articles/331746/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №8 (4 — 11 августа 2014)', 'link': 'https://habr.com/en/articles/232879/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №13 (8 — 14 сентября 2014)', 'link': 'https://habr.com/en/articles/236757/'}\n",
      "{'date': '', 'title': 'Обзор наиболее интересных материалов по анализу данных и машинному обучению №6 (21 — 28 июля 2014)', 'link': 'https://habr.com/en/articles/231323/'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def scrape_habr_articles(queries):\n",
    "    base_url = 'https://habr.com'\n",
    "    articles = []\n",
    "\n",
    "    for query in queries:\n",
    "        url = f'{base_url}/search/?q={query}&target_type=posts&order=relevance'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        articles_list = soup.find_all('article', class_='tm-articles-list__item')\n",
    "        for article in articles_list:\n",
    "            date_element = article.find('span', class_='tm-article-snippet__datetime-published')\n",
    "            if date_element is not None:\n",
    "                date = date_element.text.strip()\n",
    "            else:\n",
    "                date = ''\n",
    "\n",
    "            title_element = article.find('h2', class_=\"tm-title tm-title_h2\")\n",
    "            if title_element is not None:\n",
    "                title_link = title_element.find('a')\n",
    "                if title_link is not None:\n",
    "                    link_relative = title_link.get('href', '')\n",
    "                    link_full = urljoin(base_url, link_relative)\n",
    "                else:\n",
    "                    link_full = ''\n",
    "                title = title_element.text.strip()\n",
    "            else:\n",
    "                title = ''\n",
    "                link_full = ''\n",
    "\n",
    "            row = {'date': date, 'title': title, 'link': link_full}\n",
    "            articles.append(row)\n",
    "\n",
    "    return articles\n",
    "\n",
    "# Пример использования функции\n",
    "queries = ['python', 'анализ данных']\n",
    "articles = scrape_habr_articles(queries)\n",
    "\n",
    "# Выводим результаты\n",
    "for article in articles:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробно рассмотрим каждую строку кода:\n",
    "\n",
    "1. `import requests`: Импортируем модуль `requests`, который позволяет отправлять HTTP-запросы и получать ответы от веб-серверов.\n",
    "\n",
    "2. `from bs4 import BeautifulSoup`: Из модуля `bs4` импортируем класс `BeautifulSoup`, который используется для парсинга HTML-страниц.\n",
    "\n",
    "3. `from urllib.parse import urljoin`: Из модуля `urllib.parse` импортируем функцию `urljoin`, которая позволяет объединить базовый URL и относительный URL.\n",
    "\n",
    "4. `def scrape_habr_articles(queries)`: Определяем функцию `scrape_habr_articles`, которая принимает аргумент `queries`, содержащий список запросов.\n",
    "\n",
    "5. `base_url = 'https://habr.com'`: Задаем базовый URL для сайта `Habr`.\n",
    "\n",
    "6. `articles = []`: Создаем пустой список `articles`, в который будут добавлены статьи.\n",
    "\n",
    "7. `for query in queries:`: Начинаем цикл `for`, который перебирает каждый запрос `query` из списка `queries`.\n",
    "\n",
    "8. `url = f'{base_url}/search/?q={query}&target_type=posts&order=relevance'`: Строим URL для конкретного запроса `query`. В URL включается базовый URL `base_url` и параметры запроса, такие как поисковый запрос `q`, тип цели `target_type` и порядок сортировки `order`.\n",
    "\n",
    "9. `response = requests.get(url)`: Отправляем GET-запрос по указанному URL и сохраняем полученный ответ в переменную `response`.\n",
    "\n",
    "10. `soup = BeautifulSoup(response.text, 'html.parser')`: Создаем объект `BeautifulSoup` для парсинга HTML-кода страницы. Аргумент `response.text` содержит HTML-код полученного ответа, и `'html.parser'` указывает, что нужно использовать HTML-парсер.\n",
    "\n",
    "11. `articles_list = soup.find_all('article', class_='tm-articles-list__item')`: Ищем все элементы `'article'` с классом `'tm-articles-list__item'` внутри объекта `soup` и сохраняем результат в переменную `articles_list`.\n",
    "\n",
    "12. `for article in articles_list:`: Начинаем цикл `for`, который перебирает каждую статью `article` из списка `articles_list`.\n",
    "\n",
    "13. `date_element = article.find('span', class_='tm-article-snippet__datetime-published')`: Ищем элемент `span` с классом `'tm-article-snippet__datetime-published'` внутри статьи `article` и сохраняем результат в переменную `date_element`.\n",
    "\n",
    "14. `if date_element is not None:`: Проверяем, найден ли элемент `date_element`. Если элемент существует (не равен `None`), выполняем следующие действия. Если элемент не найден, переходим к строке 19.\n",
    "\n",
    "15. `date = date_element.text.strip()`: Извлекаем текст из элемента `date_element` с помощью метода `text` и удаляем лишние пробелы с помощью метода `strip()`. Результат сохраняется в переменную `date`.\n",
    "\n",
    "16. `else:`: Если элемент `date_element` не найден (равен `None`), выполняем следующие действия.\n",
    "\n",
    "17. `date = ''`: Присваиваем переменной `date` пустую строку.\n",
    "\n",
    "18. Аналогично строкам 13-17, переменные `title` и `link_full` извлекаются из статьи `article`. Первым шагом ищется элемент `h2` с классом `\"tm-title tm-title_h2\"`. Если элемент найден, выполняются следующие действия. Если элемент не найден, переменным `title` и `link_full` присваиваются пустые строки.\n",
    "\n",
    "19. `row = {'date': date, 'title': title, 'link': link_full}`: Создаем словарь `row`, содержащий информацию о дате, заголовке и ссылке статьи.\n",
    "\n",
    "20. `articles.append(row)`: Добавляем словарь `row` в список `articles`.\n",
    "\n",
    "21. `return articles`: Возвращаем список `articles` из функции.\n",
    "\n",
    "23. Пример использования функции:\n",
    "    - Создаем список запросов `queries`, содержащий ключевые слова или фразы для поиска статей на Habr.\n",
    "    - Вызываем функцию `scrape_habr_articles` с передачей списка запросов `queries`.\n",
    "    - Результаты сохраняются в переменной `articles`.\n",
    "\n",
    "24. `for article in articles:`: Начинаем цикл `for`, который перебирает каждую статью `article` из списка `articles`.\n",
    "\n",
    "25. `print(article)`: Выводим информацию о каждой статье на экран.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо написать функцию, которая будет основана на **поиске** по сайту [habr.com](https://habr.com/ru/search/).\n",
    "Функция в качестве параметра должна принимать **список** запросов для поиска (например, `['python', 'анализ данных']`) и на основе материалов, попавших в результаты поиска по **каждому** запросу, возвращать датафрейм вида:\n",
    "\n",
    "```\n",
    "<дата> - <заголовок> - <ссылка на материал>\n",
    "```\n",
    "\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция из обязательной части задания должна быть расширена следующим образом:\n",
    "- кроме списка ключевых слов для поиска необходимо объявить параметр с количеством страниц поисковой выдачи. Т.е. при передаче в функцию аргумента `4` необходимо получить материалы с первых 4 страниц результатов;\n",
    "- в датафрейме должны быть столбцы с полным текстом найденных материалов и количеством лайков:\n",
    "```\n",
    "<дата> - <заголовок> - <ссылка на материал> - <текст материала> - <количество лайков>\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
