{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefkong1982/netology.ru/blob/Master/Osnovy_nejronnyh_setej/Vvedenie_v_svertochnye_NS/Intro_to_NN_3__hw_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "h97RdWrNxjed"
      },
      "source": [
        "# Домашнее задание. Свёрточные сети\n",
        "\n",
        "Здесь вам предстоит построить и обучить свою первую свёрточную сеть для классификации изображений на данных CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj5T_3dxxjee"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8967u5Bzxjef"
      },
      "source": [
        "## Данные\n",
        "\n",
        "CIFAR10\n",
        "* 60000 RGB изображений размером 32x32x3\n",
        "* 10 классов: самолёты, собаки, рыбы и т.п.\n",
        "\n",
        "<img src=\"https://www.samyzaf.com/ML/cifar10/cifar1.jpg\" style=\"width:60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFMGMCFrxjef"
      },
      "source": [
        "Загрузите данные, разделите их на обучающую и тестовую выборки. Размер тестовой выборки должен быть $10^4$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf04QwsBxjef"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)\n",
        "\n",
        "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
        "\n",
        "print (X_train.shape,y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XS_kZF9xjeh"
      },
      "source": [
        "Прежде чем приступать к основной работе, стоит убедиться что загруженно именно то, что требовалось:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sih-A1Dxjeh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=[12,10])\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.xlabel(class_names[y_train[i, 0]])\n",
        "    plt.imshow(X_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iXiYWbdxjei"
      },
      "source": [
        "## Подготовка данных\n",
        "\n",
        "Сейчас каждый пиксель изображения закодирован тройкой чисел (RGB) __от 0 до 255__. Однако лучше себя показывает подход, где значения входов нейросети распределены недалеко от 0.\n",
        "\n",
        "Давайте приведём все данные в диапазон __`[0, 1]`__ — просто разделим на соответствующий коэффициент:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhIwnVXdxjei"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_val = X_val / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSRXEBo9xjej"
      },
      "source": [
        "Исполните код ниже для проверки, что все выполнено корректно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZQD2dTpxjej"
      },
      "outputs": [],
      "source": [
        "assert np.shape(X_train) == (40000, 32, 32, 3), \"data shape should not change\"\n",
        "assert 0.9 <= max(map(np.max, (X_train, X_val, X_test))) <= 1.05\n",
        "assert 0.0 <= min(map(np.min, (X_train, X_val, X_test))) <= 0.1\n",
        "assert len(np.unique(X_test / 255.)) > 10, \"make sure you casted data to float type\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdztr8BHxjej"
      },
      "source": [
        "## Архитектура сети\n",
        "\n",
        "Для начала реализуйте простую нейросеть:\n",
        "1. принимает на вход картинки размера 32 x 32 x 3;\n",
        "2. вытягивает их в вектор (`keras.layers.Flatten`);\n",
        "3. пропускает через 1 или 2 полносвязных слоя;\n",
        "4. выходной слой отдает вероятности принадлежности к каждому из 10 классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5VwlwV8xjek"
      },
      "source": [
        "Создайте полносвязную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0B2-vnExjek"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers as L\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub9pQE0Nxjek"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(32, activation='relu', input_shape=X_train.shape[1:]),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg6VYd3qxjel"
      },
      "outputs": [],
      "source": [
        "dummy_pred = model.predict(X_train[:20])\n",
        "assert dummy_pred.shape == (20, 10)\n",
        "assert np.allclose(dummy_pred.sum(-1), 1)\n",
        "print(\"Успех!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGcAp1lexjel"
      },
      "source": [
        "## Обучение сети\n",
        "\n",
        "**Задание 1.1 (обязательно)** Будем минимизировать многоклассовую кроссэкнропию с помощью __sgd__. Вам нужно получить сеть, которая достигнет __не менее 45%__ __accuracy__ на тестовых данных.\n",
        "\n",
        "__Важно:__ поскольку в y_train лежат номера классов, Керасу нужно либо указать sparse функции потерь и метрики оценки качества классификации (`sparse_categorical_crossentropy` и `sparse_categorical_accuracy`), либо конвертировать метки в one-hot формат.\n",
        "\n",
        "### Полезные советы\n",
        "* `model.compile` позволяет указать, какие метрики вы хотите вычислять.\n",
        "* В `model.fit` можно передать валидационную выборку (`validation_data=[X_val, y_val]`), для отслеживания прогресса на ней. Также рекомендуем сохранять результаты в [tensorboard](https://keras.io/callbacks/#tensorboard) или [wandb](https://docs.wandb.ai/integrations/jupyter). **Важно: логи tensorboard не получится без боли посмотреть через colab.** Workaround: скачать логи и запустить tensorboard локально или помучаться [с этим](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab).\n",
        "* По умолчанию сеть учится 1 эпоху. Совсем не факт, что вам этого хватит. Число эпох можно настроить в методе `fit` (`epochs`).\n",
        "* Ещё у Кераса есть много [полезных callback-ов](https://keras.io/callbacks/), которые можно попробовать. Например, автоматическая остановка или подбор скорости обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iVWfkypxjel"
      },
      "outputs": [],
      "source": [
        "y_train, y_val = (keras.utils.to_categorical(y) for y in (y_train, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5w_Zj5Sxjem"
      },
      "outputs": [],
      "source": [
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "             tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "             tf.keras.callbacks.EarlyStopping(patience=3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bM8coUaxjem"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "model.compile(...)\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=32, callbacks=callbacks, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZODNxMaQxjem"
      },
      "source": [
        "А теперь можно проверить качество вашей сети, выполнив код ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14l7JHe_xjem",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predict_x=model.predict(X_test)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "test_acc = accuracy_score(y_test, classes_x)\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "assert test_acc > 0.45, \"Not good enough. Back to the drawing board :)\"\n",
        "print(\" Not bad!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm_SvVrqxjen"
      },
      "source": [
        "## Карманная сверточная сеть\n",
        "\n",
        "**Задание 1.2 (обязательно)** Реализуйте небольшую свёрточную сеть. Совсем небольшую:\n",
        "1. Входной слой\n",
        "2. Свёртка 3x3 с 10 фильтрами\n",
        "3. Нелинейность на ваш вкус\n",
        "4. Max-pooling 2x2\n",
        "5. Вытягиваем оставшееся в вектор (Flatten)\n",
        "6. Полносвязный слой на 100 нейронов\n",
        "7. Нелинейность на ваш вкус\n",
        "8. Выходной полносвязный слой с softmax\n",
        "\n",
        "Обучите её так же, как и предыдущую сеть. Если всё хорошо, у вас получится accuracy не меньше __50%__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu_Sg2sCxjeo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "new_model = tf.keras.models.Sequential([...])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiJ8rBiV-klJ"
      },
      "outputs": [],
      "source": [
        "new_callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='new_model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "             tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "             tf.keras.callbacks.EarlyStopping(patience=3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L06mGJx7-o-d"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "new_model.compile(...)\n",
        "new_model.fit(X_train, y_train, batch_size=16, epochs=32, callbacks=new_callbacks, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37ZT8T4xjeo"
      },
      "source": [
        "Давайте посмотрим, смогла ли карманная сверточная сеть побить заданный порог по качеству:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAYvMxhTxjep"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predict_x = new_model.predict(X_test)\n",
        "classes_x = np.argmax(predict_x,axis=1)\n",
        "\n",
        "test_acc = accuracy_score(y_test, classes_x)\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "assert test_acc > 0.50, \"Not good enough. Back to the drawing board :)\"\n",
        "print(\" Not bad!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "How0uQPzxjep"
      },
      "source": [
        "## Учимся учить\n",
        "\n",
        "А теперь научимся сравнивать кривые обучения моделей — зависимости значения accuracy от количества итераций.\n",
        "\n",
        "Вам потребуется реализовать _экспериментальный стенд_ — вспомогательный код, в который вы сможете подать несколько архитектур и методов обучения, чтобы он их обучил и вывел графики кривых обучения. Это можно сделать с помощью `keras.callbacks` — `TensorBoard` или `History`.\n",
        "\n",
        "Будьте морально готовы, что на обучение уйдёт _много времени_. Даже если вы ограничитесь 10 эпохами. Пока идёт обучение, вы можете переключиться на другие задания или заняться чем-нибудь приятным: поспать, например."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwmdGNIHxjep"
      },
      "source": [
        "**Задание 1.3 (опционально)** Попробуйте использовать различные методы оптимизации (sgd, momentum, adam) с параметрами по умолчанию. Какой из методов работает лучше?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsF9iIFGxjeq"
      },
      "source": [
        "Для удобства напишем класс Evaluator, который принимает в себя дикты виды {имя_оптимайзера: инстанс}, {имя модели: инстанс} и обучает всевозможные комбинации моделей с оптимайзерами при помощи метода fit (попутно записывая логи отдельно для каждой модели). Также пригодится метод evaluate для отображения итоговых скоров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBtU0x2X5gmG"
      },
      "source": [
        "Пользоваться классом не обязательно. По умолчанию класс использует tensorboard. Если вы выше использовали wandb -- советуем дописать callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6pRKzaKxjeq"
      },
      "outputs": [],
      "source": [
        "class Evaluator(list):\n",
        "    def __init__(self, models, optimizers='adam', loss=keras.losses.categorical_crossentropy,\n",
        "                 metrics=[keras.metrics.categorical_accuracy]):\n",
        "        '''\n",
        "            models: dict {name: model}\n",
        "            optimizers: list of optimizers or just one optimizer\n",
        "        '''\n",
        "        if not isinstance(models, dict):\n",
        "            models = {'single_model': models}\n",
        "        if not isinstance(optimizers, dict):\n",
        "            optimizers = {str(optimizers.__class__): optimizers}\n",
        "        super().__init__([(model_name, keras.models.clone_model(model), optimizer_name, optimizer)\n",
        "                          for model_name, model in models.items()\n",
        "                          for optimizer_name, optimizer in optimizers.items()])\n",
        "        for _, model, _, optimizer in self:\n",
        "            model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    def fit(self, X, y, validation_data=(), max_epochs=100, verbose=0, callbacks=[], batch_size=32):\n",
        "        if not isinstance(callbacks, list):\n",
        "            callbacks = [callbacks]\n",
        "        for model_name, model, optimizer_name, optimizer in tqdm_notebook(self):\n",
        "            model.fit(X, y, validation_data=validation_data or None, epochs=max_epochs, verbose=verbose,\n",
        "                      batch_size=batch_size, callbacks=callbacks + [keras.callbacks.TensorBoard(\n",
        "                          log_dir='./logs/{}_{}'.format(model_name, optimizer_name))])\n",
        "\n",
        "    def fit_generator(self, X, y, validation_data=(), max_epochs=100, verbose=1, callbacks=[], batch_size=32):\n",
        "        datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "        if not isinstance(callbacks, list):\n",
        "            callbacks = [callbacks]\n",
        "        for model_name, model, optimizer_name, optimizer in tqdm_notebook(self):\n",
        "            model.fit_generator(datagen.flow(X, y, batch_size=batch_size), epochs=max_epochs,\n",
        "                validation_data=validation_data or None, verbose=verbose,\n",
        "                callbacks=callbacks + [keras.callbacks.TensorBoard(\n",
        "                    log_dir='./logs/{}_{}'.format(model_name, optimizer_name))])\n",
        "\n",
        "    def evaluate(self, X, y, metric):\n",
        "        for model_name, model, optimizer_name, _ in self:\n",
        "            print('Final score of {}_{} is {}'.format(model_name, optimizer_name,\n",
        "                  metric(y_test, model.predict(X_test).argmax(axis=1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpAWyAs7xjer"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLtng4Cwxjer"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "## TODO\n",
        "optimizers = {...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQJqV2vjxjes"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator(model, optimizers=optimizers)\n",
        "evaluator.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
        "evaluator.evaluate(X_test, y_test, accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haAsE3xcCPLU"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFMVTSbtxjes"
      },
      "source": [
        "Прокомментируйте полученные результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVkaJnLWxjet"
      },
      "source": [
        "**Задание 1.4 (опционально)** Добавьте нормализацию по батчу (`BatchNormalization`) между свёрткой и активацией. Попробуйте использовать несколько нормализаций — в свёрточных и полносвязных слоях."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppe0LGStxjet"
      },
      "source": [
        "Для удобства реализуем класс Models, который по сути будет являться списком моделей с двумя методами: add (добавить слой ко всем моделям) и add_create (создать новую модель на основе базовой с дополнительным слоем). Пользоваться им необязательно, но вдруг :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zX9hd6Kxjet"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class Models(OrderedDict):\n",
        "    def __init__(self, models):\n",
        "        if not isinstance(models, dict):\n",
        "            models = OrderedDict({'base_model': models})\n",
        "        super().__init__(models)\n",
        "\n",
        "    def add(self, layer):\n",
        "        for name, model in self.items():\n",
        "            model.add(layer)\n",
        "\n",
        "    def add_create(self, name, layer):\n",
        "        base_model = next(iter(self.items()))[1]\n",
        "        new_model = keras.models.clone_model(base_model)\n",
        "        new_model.add(layer)\n",
        "        self.update({name: new_model})\n",
        "\n",
        "    def add_update(self, name, layer):\n",
        "        base_model = self[next(reversed(self))]\n",
        "        new_model = keras.models.clone_model(base_model)\n",
        "        new_model.add(layer)\n",
        "        self.update({name: new_model})\n",
        "\n",
        "# Example of usage\n",
        "# models = Models(keras.Sequential())\n",
        "# models.add(L.InputLayer(input_shape=(32, 32, 3)))\n",
        "# models.add(L.Convolution2D(filters=10, kernel_size=(3, 3)))\n",
        "# models.add(L.MaxPooling2D())\n",
        "# models.add_create('conv_batchnorm', L.BatchNormalization())\n",
        "# models.add(L.Activation('relu'))\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORtpt21G31YV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUBUmZoB0Izj"
      },
      "source": [
        "Прокомментируйте полученные результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBUuoOXf3yMx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Doml67xjev"
      },
      "source": [
        "**Задание 1.5 (опционально)** Посмотрите на batch_size (параметр model.fit) - при большем батче модель будет быстрее проходить эпохи, но с совсем огромным батчом вам потребуется больше эпох для сходимости (т.к. сеть делает меньше шагов за одну эпоху).\n",
        "Найдите такое значение, при котором модель быстрее достигает точности 55%. **Hint**: используйте early stopping callback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1GsMtyIxjew"
      },
      "source": [
        "**Задание 1.6 (опционально)** Попробуйте найти такую комбинацию метода обучения и нормализации, при которой сеть имеет наилучшую кривую обучения. Поясните, что вы понимаете под \"наилучшей\" кривой обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-unmmw3Txjey"
      },
      "source": [
        "## Свёрточная нейросеть здорового человека\n",
        "\n",
        "**Задание 1.7 (обязательно попытаться)** Наигравшись выше, обучим большую свёрточную сеть, которая даст на тестовой выборке __accuracy больше 80%__. В этом задании вам потребуется провести эксперименты, сравнив их между собой в конце. Возможно, может быть несколько проще, если писать выводы во время или сразу после каждого эксперимента, после чего сделать общие выводы.\n",
        "\n",
        "Рекомендуем начать с лучшей модели предыдущего задания и постепенно её улучшать. Вы можете использовать всё, что угодно: любые активации, сколь угодно большие свёрточные слои и глубокие сети. Единственное ограничение: __нельзя использовать предобученные сети и дополнительные данные__.\n",
        "\n",
        "### Полезные советы\n",
        "* Для начала, неплохо бы научить что-нибудь побольше, чем 10 фильтров 3x3.\n",
        "* __Главное правило: одно изменение на эксперимент__. Если у вас есть 2 идеи по улучшению сети, сначала попробуйте их независимо. Может оказаться, что одно из них дало __+10%__ точности а другое __-7%__. А вы так и будете думать, что сделали 2 полезных изменения которые в сумме дают __+3%__. Если какая-то идея не работает — даже если она вам нравится - опишите ее и выкидывайте из дальнейших экспериментов.\n",
        "* __Be careful or you will dropout__. Дропаут (`L.Dropout`) может позволить вам обучить в несколько раз бОльшую сеть без переобучения, выжав несколько процентов качества. Это круто, но не стоит сразу ставить dropout 50%. Во-первых, слишком сильный дропаут только ухудшит сеть (underfitting). Во-вторых, даже если дропаут улучшает качество, он замедляет обучение. Рекомендуем начинать с небольшого дропаута, быстро провести основные эксперименты, а потом жахнуть в 2 раза больше нейронов и дропаута ~~на ночь~~.\n",
        "* __Аугментация данных__. Если котика слегка повернуть и подрезать (простите), он всё равно останется котиком. А в керасе есть [удобный класс](https://keras.io/preprocessing/image/), который поставит подрезание котиков на поток. Ещё можно сделать этот трюк в тесте: вертим картинку 10 раз, предсказываем вероятности и усредняем. Только один совет: прежде, чем учить, посмотрите глазами на аугментированные картинки. Если вы сами не можете их различить, то и сеть не сможет.\n",
        "* __Don't just stack more layers__. Есть более эффективные способы организовать слои, чем простой Sequential. Вот пара идей: [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions](https://arxiv.org/abs/1608.06993). Только не копируйте архитектуру подчистую — вам скорее всего хватит меньшего размера.\n",
        "* __Долго != плохо__. Более глубокие архитектуры обычно требуют бОльше эпох до сходимости. Это значит, что в первые несколько эпох они могут быть хуже менее глубоких аналогов. Дайте им время, запаситесь чаем и обмажьтесь batch-norm-ом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPxrsPf9Uwkx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEqpWz_OWUR-"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "split = 45000\n",
        "dg_x_train, dg_x_val = X_train[:split], X_train[split:]\n",
        "dg_y_train, dg_y_val = y_train[:split], y_train[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJkfhCNZ2ZEs"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "final_model = tf.keras.models.Sequential([...])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPB8KYQGFFiA"
      },
      "outputs": [],
      "source": [
        "final_callbacks = [tf.keras.callbacks.EarlyStopping(patience=5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rQsupd1Idpf"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(final_model, '123.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIk4ANp6FQJ4"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "final_model.compile(...)\n",
        "final_model.fit(datagen.flow(dg_x_train, dg_y_train, batch_size=16), epochs=32, callbacks=final_callbacks, validation_data=val_datagen.flow(dg_x_val, dg_y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mm6fAOTxje1"
      },
      "source": [
        "Момент истины: проверьте, какого качества достигла ваша сеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgUcJYLzxje2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predict_x=final_model.predict(X_test)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "test_acc = accuracy_score(y_test, classes_x)\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "if test_acc > 0.8:\n",
        "    print(\"Это победа!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjZo-jifxje2"
      },
      "source": [
        "А теперь, опишите свои <s>ощущения</s> результаты от проведенных экспериментов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t_pIaUdUxje2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}